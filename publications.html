
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Publications</title>
  <meta name="description" content="Homepage for Lanzhe Guo.">

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" id="bulma" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.6.0/css/bulma.min.css" />
  <link rel="stylesheet" type="text/css" href="/styles/base.css">
  <link rel="stylesheet" type="text/css" href="/styles/academicons.min.css">

  <link rel="canonical" href="http://www.guolz.com/publications">
</head>

  <body>
    <section class="hero is-fullheight">
      <div class="hero-head">
        <nav class="navbar" role="navigation">
  <div class="navbar-brand">
    <a class="navbar-item" href="/">
      <strong>Lanzhe Guo (郭 兰哲)</strong>
    </a>

    <div class="navbar-burger" data-target="navbar-main">
      <span></span>
      <span></span>
      <span></span>
    </div>
  </div>

  <div class="navbar-menu" id="navbar-main">
    <div class="navbar-start">
      <!-- navbar items -->
      <a href="/" class="navbar-item">
        About
      </a>
      <a class="navbar-item" href="/publications">
        Publications
      </a>
      <a class="navbar-item" href="/resume.pdf">
        Resume
      </a>
      <a class="navbar-item" href="/code">
        Code
      </a>
      <a class="navbar-item" href="/share">
        Share
      </a>
    </div>

    <div class="navbar-end">
        <!-- navbar items -->
        <div class="navbar-item">
          <a href="mailto:guolz@lamda.nju.edu.cn" class="button is-white">
            <i class="fa fa-lg fa-envelope-o" aria-hidden="true"></i>
          </a>
          <a href="https://github.com/JLUNeverMore" class="button is-white">
            <i class="fa fa-lg fa-github" aria-hidden="true"></i>
          </a>
          <a href="https://www.zhihu.com/people/gzxl" class="button is-white">
              <img src="images/zhihu.png" width="20" height="20">
          </a>
          <!--<a href="https://www.douban.com/people/pluskid/" class="button is-white">
            <img src="/images/douban.png" width="20" height="20">
          </a>-->
        </div>
      </div>
    </div>
  </nav>

      </div>

      <div class="hero-body">
        <div class="container">
  <article class="media">
    <div class="media-content">
      <div class="content">
        <h1>Publications</h1>
      </div>
    </div>
  </article>

  <article class="media">
    <div class="media-content">
      <div class="content">
        <p>
        <b>Lan-Zhe Guo</b>, Yu-Feng Li. <em>A General Formulation for Safely Exploiting Weakly Supervised Data</em>.
        In: Proceedings of the 32nd AAAI conference on Artificial Intelligence (AAAI'18), New Orleans, LA.
        <a class="tag" href="/pdf/aaai18.pdf">PDF</a>
        </p>
        <p>
          Weakly supervised data is an important machine learning data
to help improve learning performance. However, recent results
indicate that machine learning techniques with the usage
of weakly supervised data may sometimes cause performance
degradation. Safely leveraging weakly supervised data is important,
whereas there is only very limited effort, especially
on a general formulation to help provide insight to guide
safe weakly supervised learning. In this paper we present a
scheme that builds the final prediction results by integrating
several weakly supervised learners. Our resultant formulation
brings two advantages. i) For the commonly used convex loss
functions in both regression and classification tasks, safeness
guarantees exist under a mild condition; ii) Prior knowledge
related to the weights of base learners can be embedded in a
flexible manner. Moreover, the formulation can be addressed
globally by simple convex quadratic or linear program efficiently.
Experiments on multiple weakly supervised learning
tasks such as label noise learning, domain adaptation and
semi-supervised learning validate the effectiveness
        </p>
      </div>
    </div>
  </article>
  <article class="media">
    <div class="media-content">
      <div class="content">
        <p>
        Tong Wei, <b>Lan-Zhe Guo</b>, Yu-Feng Li, Wei Gao. <em>Learning Safe Multi-Label Prediction for Weakly Labeled Data</em>. 
        Machine Learning, 2018, 107(4): 703-725.
        <a class="tag" href="/pdf/acml17.pdf">PDF</a>
        </p>
        <p>
          In this paper we study multi-label learning with weakly labeled data,
i.e., labels of training examples are incomplete. This includes, e.g., (i) semi-supervised
multi-label learning where completely labeled examples are partially known; (ii)
weak label learning where relevant labels of examples are partially known; iii) extended
weak label learning where relevant and irrelevant labels of examples are
partially known. Weakly labeled data commonly occur in real applications, e.g.,
image classification, document categorization. Previous studies often expect that
learning methods with the use of weakly labeled data improve learning performance,
as more data are employed. This, however, is not always the cases in reality.
Using more weakly labeled data may sometimes degenerate learning performance.
It is desirable to learn safe multi-label prediction that will not hurt performance
when weakly labeled data is used. In this work we optimize multi-label evaluation
metrics (F1 score and Top-k precision) given that ground-truth label assignments
are realized by a convex combination of basic multi-label learners. To cope with
infinite number of possible ground-truth label assignments, cutting-plane strategy
is adopted to iteratively generate the most helpful label assignments. The
whole optimization is cast as a series of simple linear programs in an efficient
manner. Extensive experiments on three weakly labeled learning tasks, namely,
i) semi-supervised multi-label learning; ii) weak-label learning and iii) extended
weak-label learning, show that our proposal clearly improves the safeness in comparison
to many state-of-the-art methods.
        </p>
      </div>
    </div>
  </article>
  <article class="media">
        <div class="media-content">
          <div class="content">
            <p>
            <b>Lan-Zhe Guo</b>, Tao Han, Yu-Feng Li. <em>Max-Margin GCN: Robust Semi-Supervised Representation Learning for Graph-Structured Data</em>. 
            Sumbitted to NIPS 2018.
            <!--a class="tag" href="/pdf/acml17.pdf">PDF</a!-->
            </p>
          </div>
        </div>
      </article>
</div>



      </div>
      <div class="hero-foot">
        <footer class="footer">
  <div class="container">
    <div class="content has-text-right is-size-7">
      <p>
        © 2018 by Lan-Zhe Guo. All Rights Reserved.
        &nbsp;&nbsp;
          Links:&nbsp;&nbsp;
          <a target="www.sshao.com" href="#">Shuai Shao</a>
      </p>
    </div>
  </div>
</footer>

<script async type="text/javascript" src="/javascript/bulma.js"></script>

      </div>
    </section>
  </body>
</html>
